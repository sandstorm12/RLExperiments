# RLExperiments

A set of simple problems solved using (D)RL


## Outline

| Task | Demo |
|------|------|
| [`CartPole-v1` using `A2C`](a2c_cartpole_v1) | <img src="a2c_cartpole_v1/data/output.gif" width="400" /> |
| [`MountainCar-v0` using `DQN`](dqn_mountaincar_v0) | <img src="dqn_mountaincar_v0/data/output.gif" width="400" /> |
| [`MountainCar-v0` using a custom `DQN`](custom_dqn_mountaincar_v0) | <img src="custom_dqn_mountaincar_v0/data/output.gif" width="400" /> |
| [`MountainCar-v0` using a custom `ConvolutionalDQN`](custom_cdqn_mountaincar_v0) | <img src="custom_cdqn_mountaincar_v0/data/output.gif" width="400" /> |
| [`LunarLander-v2` using a custom `DQN`](custom_dqn_lunarlander_v2) | <img src="custom_dqn_lunarlander_v2/data/output.gif" width="400" /> |
| [`LunarLander-v2` using a custom `ConvolutionalDQN`](custom_cdqn_lunarlander_v2) | <img src="custom_cdqn_lunarlander_v2/data/output.gif" width="400" /> |





## Urgent issues and future work

1. *Nothing so far*


## Issues and future work

1. Feature: Implement a custom `DQN` to solve the `MountainCar_v0` environment
2. Feature: Implement a custom `policy-based` model to solve the `CartPole_v1` environment
3. Feature: Implement a custom `A2C` model to solve the `CartPole_v1` environment
4. Feature: Implement a vision-based `DQN` to solve the `MountainCar_v0` enviroment
5. Feature: Implement a vision-based `A2C` to solve the `CartPole_v1` enviroment
6. Feature: Solve `Moon Lander` using a custom agent
7. Feature: Add model architecture visualization to each project
8. Feature: Add train and test accuracy plots for each project
9. Feature: Add performance benchmark to all projects
10. Feature: Solve `MountainCar-v0` without reward-shaping
11. Feature: Implement `Prioritized Experience Replay (PER)`


## Contributors
1. Hamid Mohammadi: <sandstormeatwo@gmail.com>
